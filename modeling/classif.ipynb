{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version from iris dataset. Uncomment below.\n",
    "\n",
    "# path = kagglehub.dataset_download(\"uciml/iris\")\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# # Copy the files to data folder\n",
    "# shutil.copytree(path, \"./data\", dirs_exist_ok=True)\n",
    "# print(\"Dataset saved to ./data directory\")\n",
    "\n",
    "# # Clean up the temporary path\n",
    "# shutil.rmtree(path)\n",
    "# print(\"Temporary files cleaned up\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/Iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1750984050631, experiment_id='1', last_update_time=1750984050631, lifecycle_stage='active', name='iris-classification-dev', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")  # Use the service name from docker-compose\n",
    "mlflow.set_experiment(\"iris-classification-dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for data validation and cleaning\n",
    "class DataValidator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, missing_threshold=0.3, variance_threshold=0.01):\n",
    "        self.missing_threshold = missing_threshold\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.columns_to_drop = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        logger.info(\"Starting data validation and cleaning...\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_counts = X.isnull().sum()\n",
    "        missing_percentages = (missing_counts / len(X)) * 100\n",
    "        \n",
    "        logger.info(f\"Missing values per column: {missing_percentages.to_dict()}\")\n",
    "        \n",
    "        # Store columns to drop\n",
    "        self.columns_to_drop = missing_percentages[missing_percentages > self.missing_threshold * 100].index\n",
    "        \n",
    "        if len(self.columns_to_drop) > 0:\n",
    "            logger.warning(f\"Dropping columns with >{self.missing_threshold*100}% missing values: {list(self.columns_to_drop)}\")\n",
    "        \n",
    "        # Store feature names for variance check\n",
    "        numeric_columns = X.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_columns) > 0:\n",
    "            variance_selector = VarianceThreshold(threshold=self.variance_threshold)\n",
    "            variance_selector.fit(X[numeric_columns])\n",
    "            support_mask = variance_selector.get_support()\n",
    "            if support_mask is not None:\n",
    "                low_variance_cols = numeric_columns[~support_mask]\n",
    "                if len(low_variance_cols) > 0:\n",
    "                    logger.warning(f\"Columns with low variance: {list(low_variance_cols)}\")\n",
    "            else:\n",
    "                logger.warning(\"Variance selector support mask is None\")\n",
    "        \n",
    "        self.feature_names = X.columns\n",
    "        logger.info(\"Data validation completed\")\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Drop columns with too many missing values\n",
    "        if self.columns_to_drop is not None and len(self.columns_to_drop) > 0:\n",
    "            X = X.drop(columns=self.columns_to_drop)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"RandomForestClassifier\"\n",
    "MODEL_VERSION = \"v0.0.0\"\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start mlflow run\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preparing features and target...\n",
      "INFO:__main__:Training set size: 105\n",
      "INFO:__main__:Test set size: 45\n",
      "INFO:__main__:Fitting the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Performing cross-validation...\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dict: {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Cross-validation scores: [0.95238095 0.95238095 0.95238095 0.9047619  0.95238095]\n",
      "INFO:__main__:Mean CV accuracy: 0.9429 (+/- 0.0381)\n",
      "INFO:__main__:Test set accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting target from features\n",
    "logger.info(\"Preparing features and target...\")\n",
    "features = data.drop(['Id', 'Species'], axis=1)\n",
    "target = data['Species']\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Print mapping\n",
    "print(\"Mapping dict:\",\n",
    "    {label: idx for idx, label in enumerate(label_encoder.classes_)})\n",
    "\n",
    "# Create a machine learning pipeline with the following steps:\n",
    "# 1. Data validation: Check for missing values and low variance features\n",
    "# 2. Imputation: Fill missing values using mean strategy\n",
    "# 3. Scaling: Standardize features to have zero mean and unit variance\n",
    "# 4. Classification: Use Decision Tree classifier for prediction\n",
    "pipeline = Pipeline([\n",
    "    ('validator', DataValidator(missing_threshold=0.3, variance_threshold=0.01)),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target_encoded, test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, stratify=target_encoded\n",
    ")\n",
    "\n",
    "logger.info(f\"Training set size: {X_train.shape[0]}\")\n",
    "logger.info(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Fit the pipeline\n",
    "logger.info(\"Fitting the pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "logger.info(\"Performing cross-validation...\")\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "logger.info(f\"Cross-validation scores: {cv_scores}\")\n",
    "mean_cv_accuracy = cv_scores.mean()\n",
    "logger.info(f\"Mean CV accuracy: {mean_cv_accuracy:.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Test set evaluation\n",
    "test_accuracy = pipeline.score(X_test, y_test)\n",
    "logger.info(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/.local/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "#pack encoder withn model\n",
    "class ModelWithEncoder(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model, label_encoder):\n",
    "        self.model = model\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def predict(self, model_input):\n",
    "        # Handle string (JSON)\n",
    "        if isinstance(model_input, str):\n",
    "            model_input = json.loads(model_input)\n",
    "\n",
    "        # Handle dict (single row)\n",
    "        if isinstance(model_input, dict):\n",
    "            model_input = pd.DataFrame([model_input])\n",
    "\n",
    "        # Handle Series (single row)\n",
    "        elif isinstance(model_input, pd.Series):\n",
    "            model_input = model_input.to_frame().T\n",
    "\n",
    "        # Handle flat list (single row) or list of lists (multiple rows)\n",
    "        elif isinstance(model_input, list):\n",
    "            # Infer feature count from training data (optional)\n",
    "            if all(isinstance(x, (int, float)) for x in model_input):\n",
    "                model_input = pd.DataFrame([model_input], columns=self.model.feature_names_in_)\n",
    "            else:\n",
    "                model_input = pd.DataFrame(model_input, columns=self.model.feature_names_in_)\n",
    "\n",
    "        # Already a DataFrame\n",
    "        elif not isinstance(model_input, pd.DataFrame):\n",
    "            raise TypeError(f\"Unsupported input type: {type(model_input)}\")\n",
    "\n",
    "        # Predict\n",
    "        encoded_preds = self.model.predict(model_input)\n",
    "        return self.label_encoder.inverse_transform(encoded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/27 18:45:23 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "Registered model 'RandomForestClassifier' already exists. Creating a new version of this model...\n",
      "2025/06/27 18:45:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RandomForestClassifier, version 38\n",
      "Created version '38' of model 'RandomForestClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run casual-stag-913 at: http://0.0.0.0:5000/#/experiments/1/runs/63fe3d862b9f40448fe12f23f3ff7ef7\n",
      "üß™ View experiment at: http://0.0.0.0:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Log the model and label encoder\n",
    "rfc_model = ModelWithEncoder(pipeline, label_encoder)\n",
    "input_example = pd.DataFrame(X_test[:5], columns=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"])\n",
    "signature = infer_signature(X_train, pipeline.predict(X_train))\n",
    "\n",
    "# Log the model with MLflow\n",
    "mlflow.pyfunc.log_model(\n",
    "    python_model=rfc_model,\n",
    "    name=MODEL_NAME,\n",
    "    input_example=input_example,\n",
    "    signature=signature,\n",
    "    registered_model_name=MODEL_NAME\n",
    ")\n",
    "# Log all parameters and metrics to MLflow\n",
    "mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "mlflow.log_param(\"model_version\", MODEL_VERSION)\n",
    "mlflow.log_param(\"test_size\", TEST_SIZE)\n",
    "mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "mlflow.log_param(\"packed_model\", True)\n",
    "mlflow.log_metric(\"mean_cv_accuracy\", mean_cv_accuracy)\n",
    "mlflow.log_metric(\"test_set_accuracy\", test_accuracy)\n",
    "\n",
    "# Ende MlFlow experiment run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving model locally. Uncomment below.\n",
    "\n",
    "# # Create model directory\n",
    "# os.makedirs(\"./model\", exist_ok=True)\n",
    "\n",
    "# # Save the model with timestamp\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# model_filename = f\"./model/decision_tree_{timestamp}.pkl\"\n",
    "# label_encoder_filename = f\"./model/label_encoder_{timestamp}.pkl\"\n",
    "\n",
    "# with open(model_filename, 'wb') as f:\n",
    "#     pickle.dump(pipeline, f)\n",
    "\n",
    "# with open(label_encoder_filename, 'wb') as f:\n",
    "#     pickle.dump(label_encoder, f)\n",
    "\n",
    "# logger.info(f\"Model saved to: {model_filename}\")\n",
    "# logger.info(f\"Label encoder saved to: {label_encoder_filename}\")\n",
    "\n",
    "# # Save target_encoded for model serving\n",
    "# target_encoded_filename = f\"./model/target_encoded_{timestamp}.pkl\"\n",
    "\n",
    "# with open(target_encoded_filename, 'wb') as f:\n",
    "#     pickle.dump(target_encoded, f)\n",
    "\n",
    "# logger.info(f\"Target encoded data saved to: {target_encoded_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "INFO:__main__:[Unpacked] Predicted species for input [[0.2, 5.1, 3.5, 1.4]]: [1]\n",
      "INFO:__main__:[Unpacked] Predicted species for input [[0.2, 5.1, 3.5, 1.4]]: Iris-versicolor\n",
      "INFO:__main__:[Packed] Predicted species for input {'SepalLengthCm': 5.1, 'SepalWidthCm': 3.5, 'PetalLengthCm': 1.4, 'PetalWidthCm': 0.2}: Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# Showing differences between unpacked and packed models\n",
    "\n",
    "# Unpacked\n",
    "input = [[0.2,5.1,3.5,1.4]]\n",
    "\n",
    "result = pipeline.predict(input)\n",
    "logger.info(f\"[Unpacked] Predicted species for input {input}: {result}\")\n",
    "result_species = label_encoder.inverse_transform(result)\n",
    "logger.info(f\"[Unpacked] Predicted species for input {input}: {result_species[0]}\")\n",
    "\n",
    "# Packed\n",
    "input = {\n",
    "    \"SepalLengthCm\": 5.1,\n",
    "    \"SepalWidthCm\": 3.5,\n",
    "    \"PetalLengthCm\": 1.4,\n",
    "    \"PetalWidthCm\": 0.2\n",
    "}\n",
    "\n",
    "result_packed = rfc_model.predict(model_input=input)\n",
    "logger.info(f\"[Packed] Predicted species for input {input}: {result_packed[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully retrieved production model version: 36\n"
     ]
    }
   ],
   "source": [
    "# Import MLflow client for model registry operations\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# Initialize MLflow client to interact with model registry\n",
    "client = MlflowClient()\n",
    "# del label_encoder\n",
    "# Check the production model version using alias\n",
    "try:\n",
    "    # Get model version associated with 'production' alias\n",
    "    model_info = client.get_model_version_by_alias(MODEL_NAME, \"production\")\n",
    "    logger.info(f\"Successfully retrieved production model version: {model_info.version}\")\n",
    "except Exception as e:\n",
    "    # Log error if unable to retrieve production model version\n",
    "    logger.error(f\"Failed to retrieve production model version: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ModelVersion: aliases=['production'], creation_timestamp=1751039742191, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1751039742191, metrics=None, model_id=None, name='RandomForestClassifier', params=None, run_id='893b7e745bac4159a81e753e25098294', run_link='', source='models:/m-5a66a96ce3c242e6ab72398f70a0d17e', status='READY', status_message=None, tags={}, user_id='', version='36'>\n"
     ]
    }
   ],
   "source": [
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading production model from registry: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 11.88it/s]\n",
      "INFO:__main__:Production model loaded successfully for inference\n"
     ]
    }
   ],
   "source": [
    "# Load production model from MLflow model registry for inference\n",
    "logger.info(f\"Loading production model from registry: {MODEL_NAME}\")\n",
    "model_uri = f\"models:/{MODEL_NAME}@production\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "logger.info(\"Production model loaded successfully for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded predictions: ['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "# Predict and decode\n",
    "input = {\n",
    "    \"SepalLengthCm\": 5.1,\n",
    "    \"SepalWidthCm\": 3.5,\n",
    "    \"PetalLengthCm\": 1.4,\n",
    "    \"PetalWidthCm\": 0.2\n",
    "}\n",
    "pred = model.predict(input)\n",
    "\n",
    "print(\"Decoded predictions:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training a more robust RandomForest model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fitting the robust RandomForest pipeline...\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Starting data validation and cleaning...\n",
      "INFO:__main__:Missing values per column: {'SepalLengthCm': 0.0, 'SepalWidthCm': 0.0, 'PetalLengthCm': 0.0, 'PetalWidthCm': 0.0}\n",
      "INFO:__main__:Data validation completed\n",
      "INFO:__main__:Robust model CV scores: [1.         1.         0.93333333 0.93333333 1.        ]\n",
      "INFO:__main__:Robust model mean CV accuracy: 0.9733 (+/- 0.0653)\n",
      "INFO:__main__:Robust model test accuracy: 0.9067\n",
      "INFO:__main__:Out-of-bag score: 0.9600\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 31.93it/s]\n",
      "INFO:__main__:Original model predictions shape: 75\n",
      "INFO:__main__:Original model predictions sample: ['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica']\n",
      "INFO:__main__:Simple model test accuracy: 0.9467\n",
      "INFO:__main__:Robust model improvement: -0.0400\n",
      "2025/06/27 18:54:24 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "Registered model 'RobustRandomForestClassifier' already exists. Creating a new version of this model...\n",
      "2025/06/27 18:54:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RobustRandomForestClassifier, version 7\n",
      "Created version '7' of model 'RobustRandomForestClassifier'.\n",
      "INFO:__main__:Robust RandomForest model logged as: RobustRandomForestClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run robust_randomforest_training at: http://0.0.0.0:5000/#/experiments/1/runs/0d5637253a844b6b88435e6820eee436\n",
      "üß™ View experiment at: http://0.0.0.0:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 39.28it/s]  \n",
      "INFO:__main__:Testing robust RandomForest model predictions:\n",
      "INFO:__main__:Input 1: {'SepalLengthCm': 5.1, 'SepalWidthCm': 3.5, 'PetalLengthCm': 1.4, 'PetalWidthCm': 0.2} -> Prediction: ['Iris-setosa']\n",
      "INFO:__main__:Input 2: {'SepalLengthCm': 6.3, 'SepalWidthCm': 3.3, 'PetalLengthCm': 4.7, 'PetalWidthCm': 1.6} -> Prediction: ['Iris-versicolor']\n",
      "INFO:__main__:Input 3: {'SepalLengthCm': 7.2, 'SepalWidthCm': 3.0, 'PetalLengthCm': 5.8, 'PetalWidthCm': 1.6} -> Prediction: ['Iris-virginica']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Summary:\n",
      "              Model  Test Accuracy  CV Mean   CV Std Model Complexity Training Time\n",
      "Simple RandomForest       0.946667 0.942857 0.019048              Low          Fast\n",
      "Robust RandomForest       0.906667 0.973333 0.032660           Medium        Medium\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a more robust model using the existing pipeline structure\n",
    "\n",
    "# Import additional libraries for more robust models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "logger.info(\"Training a more robust RandomForest model...\")\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")  # Use the service name from docker-compose\n",
    "mlflow.set_experiment(\"iris-classification-dev\")\n",
    "\n",
    "# Log the robust model with a different name\n",
    "ROBUST_MODEL_NAME = \"RobustRandomForestClassifier\"\n",
    "TEST_SIZE = 0.5\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target_encoded, test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, stratify=target_encoded\n",
    ")\n",
    "\n",
    "\n",
    "# Create a heavier RandomForest classifier \n",
    "# Forcing an Overfit\n",
    "robust_classifier = RandomForestClassifier(\n",
    "    n_estimators=500,  \n",
    "    max_depth=15,      \n",
    "    min_samples_split=2,  \n",
    "    min_samples_leaf=5,   \n",
    "    max_features='sqrt',  \n",
    "    bootstrap=True,       \n",
    "    oob_score=True,       \n",
    "    random_state=42,\n",
    "    n_jobs=-1            \n",
    ")\n",
    "\n",
    "# Use the existing pipeline structure with the robust classifier\n",
    "robust_pipeline = Pipeline([\n",
    "    ('validator', DataValidator(missing_threshold=0.3, variance_threshold=0.01)),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', robust_classifier)\n",
    "])\n",
    "\n",
    "# Train the robust model\n",
    "logger.info(\"Fitting the robust RandomForest pipeline...\")\n",
    "robust_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the robust model\n",
    "y_pred_robust = robust_pipeline.predict(X_test)\n",
    "robust_accuracy = accuracy_score(y_test, y_pred_robust)\n",
    "\n",
    "# Cross-validation for robust model\n",
    "cv_scores_robust = cross_val_score(robust_pipeline, X_train, y_train, cv=5)\n",
    "logger.info(f\"Robust model CV scores: {cv_scores_robust}\")\n",
    "logger.info(f\"Robust model mean CV accuracy: {cv_scores_robust.mean():.4f} (+/- {cv_scores_robust.std() * 2:.4f})\")\n",
    "logger.info(f\"Robust model test accuracy: {robust_accuracy:.4f}\")\n",
    "\n",
    "# Get out-of-bag score if available\n",
    "if hasattr(robust_classifier, 'oob_score_'):\n",
    "    logger.info(f\"Out-of-bag score: {robust_classifier.oob_score_:.4f}\")\n",
    "\n",
    "# Get predictions from the original simple model for comparison\n",
    "# Load the original model from MLflow registry\n",
    "original_model_uri = \"models:/RandomForestClassifier/latest\"\n",
    "original_model = mlflow.pyfunc.load_model(original_model_uri)\n",
    "\n",
    "# Convert X_test to the format expected by the MLflow model (dictionary format)\n",
    "X_test_dict = []\n",
    "for i in range(len(X_test)):\n",
    "    sample = {\n",
    "        \"SepalLengthCm\": X_test.iloc[i, 0],\n",
    "        \"SepalWidthCm\": X_test.iloc[i, 1], \n",
    "        \"PetalLengthCm\": X_test.iloc[i, 2],\n",
    "        \"PetalWidthCm\": X_test.iloc[i, 3]\n",
    "    }\n",
    "    X_test_dict.append(sample)\n",
    "\n",
    "# Get predictions from the original model\n",
    "y_pred_simple_raw = original_model.predict(X_test_dict)\n",
    "logger.info(f\"Original model predictions shape: {len(y_pred_simple_raw)}\")\n",
    "logger.info(f\"Original model predictions sample: {y_pred_simple_raw[:5]}\")\n",
    "\n",
    "# Convert predictions to numeric format for accuracy calculation\n",
    "# The MLflow model returns string predictions, so we need to convert them back to numeric\n",
    "y_pred_simple_numeric = []\n",
    "for pred in y_pred_simple_raw:\n",
    "    if isinstance(pred, list):\n",
    "        pred = pred[0]  # Extract from list if needed\n",
    "    # Convert string prediction back to numeric using label_encoder\n",
    "    numeric_pred = label_encoder.transform([pred])[0]\n",
    "    y_pred_simple_numeric.append(numeric_pred)\n",
    "\n",
    "y_pred_simple_numeric = np.array(y_pred_simple_numeric)\n",
    "simple_accuracy = accuracy_score(y_test, y_pred_simple_numeric)\n",
    "\n",
    "# Compare with simple model\n",
    "logger.info(f\"Simple model test accuracy: {simple_accuracy:.4f}\")\n",
    "logger.info(f\"Robust model improvement: {robust_accuracy - simple_accuracy:.4f}\")\n",
    "\n",
    "# Reuse the existing ModelWithEncoder class instead of creating a new one\n",
    "robust_pyfunc_model = ModelWithEncoder(robust_pipeline, label_encoder)\n",
    "\n",
    "with mlflow.start_run(run_name=\"robust_randomforest_training\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_type\": \"robust_random_forest\",\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 15,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 3,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"bootstrap\": True,\n",
    "        \"oob_score\": True\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"test_accuracy\": robust_accuracy,\n",
    "        \"cv_mean_accuracy\": cv_scores_robust.mean(),\n",
    "        \"cv_std_accuracy\": cv_scores_robust.std(),\n",
    "        \"improvement_over_simple\": robust_accuracy - simple_accuracy\n",
    "    })\n",
    "    \n",
    "    # Log the robust model using pyfunc with the same strategy as the original model\n",
    "    mlflow.pyfunc.log_model(\n",
    "        python_model=robust_pyfunc_model,\n",
    "        name=ROBUST_MODEL_NAME,\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        registered_model_name=ROBUST_MODEL_NAME\n",
    "    )\n",
    "\n",
    "logger.info(f\"Robust RandomForest model logged as: {ROBUST_MODEL_NAME}\")\n",
    "\n",
    "\n",
    "# Load and test the robust model using pyfunc\n",
    "robust_model_uri = f\"models:/{ROBUST_MODEL_NAME}/latest\"\n",
    "robust_model = mlflow.pyfunc.load_model(robust_model_uri)\n",
    "\n",
    "# Test predictions\n",
    "test_inputs = [\n",
    "    {\"SepalLengthCm\": 5.1, \"SepalWidthCm\": 3.5, \"PetalLengthCm\": 1.4, \"PetalWidthCm\": 0.2},\n",
    "    {\"SepalLengthCm\": 6.3, \"SepalWidthCm\": 3.3, \"PetalLengthCm\": 4.7, \"PetalWidthCm\": 1.6},\n",
    "    {\"SepalLengthCm\": 7.2, \"SepalWidthCm\": 3.0, \"PetalLengthCm\": 5.8, \"PetalWidthCm\": 1.6}\n",
    "]\n",
    "\n",
    "logger.info(\"Testing robust RandomForest model predictions:\")\n",
    "for i, test_input in enumerate(test_inputs):\n",
    "    prediction = robust_model.predict(test_input)\n",
    "    logger.info(f\"Input {i+1}: {test_input} -> Prediction: {prediction}\")\n",
    "\n",
    "\n",
    "# Create a comparison summary\n",
    "comparison_data = {\n",
    "    'Model': ['Simple RandomForest', 'Robust RandomForest'],\n",
    "    'Test Accuracy': [simple_accuracy, robust_accuracy],\n",
    "    'CV Mean': [cv_scores.mean(), cv_scores_robust.mean()],\n",
    "    'CV Std': [cv_scores.std(), cv_scores_robust.std()],\n",
    "    'Model Complexity': ['Low', 'Medium'],\n",
    "    'Training Time': ['Fast', 'Medium']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Model Comparison Summary:\")\n",
    "print(comparison_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
